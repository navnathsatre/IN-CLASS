{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the above doesnt work, try on prompt\n",
    "pip install --default-timeout=1000 tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your first MLP in Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8,  activation='relu'))\n",
    "model.add(Dense(8,  activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.5766 - accuracy: 0.7179 - val_loss: 0.6633 - val_accuracy: 0.6732\n",
      "Epoch 2/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.6946 - val_loss: 0.7100 - val_accuracy: 0.6417\n",
      "Epoch 3/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.6946 - val_loss: 0.7093 - val_accuracy: 0.6457\n",
      "Epoch 4/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.6984 - val_loss: 0.6675 - val_accuracy: 0.6614\n",
      "Epoch 5/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5907 - accuracy: 0.7101 - val_loss: 0.6579 - val_accuracy: 0.6850\n",
      "Epoch 6/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.7023 - val_loss: 0.6995 - val_accuracy: 0.6417\n",
      "Epoch 7/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5740 - accuracy: 0.7101 - val_loss: 0.6886 - val_accuracy: 0.6811\n",
      "Epoch 8/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.7004 - val_loss: 0.7088 - val_accuracy: 0.6811\n",
      "Epoch 9/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.6946 - val_loss: 0.6871 - val_accuracy: 0.6654\n",
      "Epoch 10/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6069 - accuracy: 0.6868 - val_loss: 0.7124 - val_accuracy: 0.6417\n",
      "Epoch 11/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5915 - accuracy: 0.7062 - val_loss: 0.6746 - val_accuracy: 0.6772\n",
      "Epoch 12/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.7023 - val_loss: 0.6448 - val_accuracy: 0.6811\n",
      "Epoch 13/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5762 - accuracy: 0.6965 - val_loss: 0.6534 - val_accuracy: 0.6772\n",
      "Epoch 14/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.7043 - val_loss: 0.6859 - val_accuracy: 0.6811\n",
      "Epoch 15/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.7004 - val_loss: 0.6736 - val_accuracy: 0.6772\n",
      "Epoch 16/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.7062 - val_loss: 0.6545 - val_accuracy: 0.6850\n",
      "Epoch 17/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6102 - accuracy: 0.7043 - val_loss: 0.6937 - val_accuracy: 0.6457\n",
      "Epoch 18/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.7043 - val_loss: 0.6739 - val_accuracy: 0.7047\n",
      "Epoch 19/250\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5871 - accuracy: 0.7004 - val_loss: 0.6746 - val_accuracy: 0.6575\n",
      "Epoch 20/250\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5825 - accuracy: 0.6965 - val_loss: 0.6780 - val_accuracy: 0.6575\n",
      "Epoch 21/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6035 - accuracy: 0.6848 - val_loss: 0.7049 - val_accuracy: 0.6732\n",
      "Epoch 22/250\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5776 - accuracy: 0.7043 - val_loss: 0.6817 - val_accuracy: 0.6654\n",
      "Epoch 23/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.7218 - val_loss: 0.6582 - val_accuracy: 0.6850\n",
      "Epoch 24/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.7023 - val_loss: 0.6747 - val_accuracy: 0.6417\n",
      "Epoch 25/250\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5805 - accuracy: 0.7160 - val_loss: 0.6905 - val_accuracy: 0.6693\n",
      "Epoch 26/250\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5898 - accuracy: 0.6984 - val_loss: 0.6584 - val_accuracy: 0.6850\n",
      "Epoch 27/250\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5759 - accuracy: 0.7023 - val_loss: 0.6662 - val_accuracy: 0.6772\n",
      "Epoch 28/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5714 - accuracy: 0.7004 - val_loss: 0.6730 - val_accuracy: 0.6614\n",
      "Epoch 29/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.7043 - val_loss: 0.6750 - val_accuracy: 0.6575\n",
      "Epoch 30/250\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5986 - accuracy: 0.6926 - val_loss: 0.6769 - val_accuracy: 0.6575\n",
      "Epoch 31/250\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.7023 - val_loss: 0.6886 - val_accuracy: 0.6890\n",
      "Epoch 32/250\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5686 - accuracy: 0.7082 - val_loss: 0.6751 - val_accuracy: 0.6614\n",
      "Epoch 33/250\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5792 - accuracy: 0.7082 - val_loss: 0.6863 - val_accuracy: 0.6457\n",
      "Epoch 34/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5733 - accuracy: 0.6965 - val_loss: 0.6752 - val_accuracy: 0.6654\n",
      "Epoch 35/250\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5672 - accuracy: 0.7121 - val_loss: 0.6926 - val_accuracy: 0.6457\n",
      "Epoch 36/250\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5745 - accuracy: 0.7062 - val_loss: 0.6777 - val_accuracy: 0.6850\n",
      "Epoch 37/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.7062 - val_loss: 0.6727 - val_accuracy: 0.6654\n",
      "Epoch 38/250\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.5671 - accuracy: 0.71 - 0s 3ms/step - loss: 0.5702 - accuracy: 0.7121 - val_loss: 0.6579 - val_accuracy: 0.6890\n",
      "Epoch 39/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.6965 - val_loss: 0.6904 - val_accuracy: 0.6575\n",
      "Epoch 40/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5672 - accuracy: 0.7082 - val_loss: 0.6768 - val_accuracy: 0.6614\n",
      "Epoch 41/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.7101 - val_loss: 0.7753 - val_accuracy: 0.6024\n",
      "Epoch 42/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.7023 - val_loss: 0.7101 - val_accuracy: 0.6457\n",
      "Epoch 43/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5679 - accuracy: 0.7082 - val_loss: 0.6817 - val_accuracy: 0.6929\n",
      "Epoch 44/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5695 - accuracy: 0.7043 - val_loss: 0.7031 - val_accuracy: 0.6614\n",
      "Epoch 45/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.7023 - val_loss: 0.7265 - val_accuracy: 0.6654\n",
      "Epoch 46/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.6965 - val_loss: 0.6957 - val_accuracy: 0.6614\n",
      "Epoch 47/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5947 - accuracy: 0.6829 - val_loss: 0.6785 - val_accuracy: 0.6693\n",
      "Epoch 48/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.7121 - val_loss: 0.6995 - val_accuracy: 0.6614\n",
      "Epoch 49/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.7043 - val_loss: 0.7298 - val_accuracy: 0.6811\n",
      "Epoch 50/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5993 - accuracy: 0.6946 - val_loss: 0.6610 - val_accuracy: 0.6890\n",
      "Epoch 51/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.6926 - val_loss: 0.6886 - val_accuracy: 0.6535\n",
      "Epoch 52/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.7121 - val_loss: 0.6776 - val_accuracy: 0.6654\n",
      "Epoch 53/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5859 - accuracy: 0.6907 - val_loss: 0.6927 - val_accuracy: 0.6850\n",
      "Epoch 54/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.7004 - val_loss: 0.6698 - val_accuracy: 0.6850\n",
      "Epoch 55/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.7082 - val_loss: 0.6719 - val_accuracy: 0.6772\n",
      "Epoch 56/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5950 - accuracy: 0.7062 - val_loss: 0.6908 - val_accuracy: 0.6614\n",
      "Epoch 57/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.6965 - val_loss: 0.6757 - val_accuracy: 0.6850\n",
      "Epoch 58/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5921 - accuracy: 0.7004 - val_loss: 0.6747 - val_accuracy: 0.6654\n",
      "Epoch 59/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7296 - val_loss: 0.6961 - val_accuracy: 0.6614\n",
      "Epoch 60/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5637 - accuracy: 0.7043 - val_loss: 0.6905 - val_accuracy: 0.6890\n",
      "Epoch 61/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.7140 - val_loss: 0.7106 - val_accuracy: 0.6457\n",
      "Epoch 62/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5710 - accuracy: 0.7004 - val_loss: 0.6917 - val_accuracy: 0.7008\n",
      "Epoch 63/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7043 - val_loss: 0.7044 - val_accuracy: 0.6575\n",
      "Epoch 64/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.7043 - val_loss: 0.6939 - val_accuracy: 0.6732\n",
      "Epoch 65/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5624 - accuracy: 0.7198 - val_loss: 0.6871 - val_accuracy: 0.6772\n",
      "Epoch 66/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5680 - accuracy: 0.7043 - val_loss: 0.6997 - val_accuracy: 0.6811\n",
      "Epoch 67/250\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.6926 - val_loss: 0.7693 - val_accuracy: 0.6339\n",
      "Epoch 68/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5810 - accuracy: 0.7140 - val_loss: 0.7385 - val_accuracy: 0.6654\n",
      "Epoch 69/250\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.7043 - val_loss: 0.7058 - val_accuracy: 0.6575\n",
      "Epoch 70/250\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.6093 - accuracy: 0.6848 - val_loss: 0.7201 - val_accuracy: 0.6417\n",
      "Epoch 71/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5754 - accuracy: 0.7160 - val_loss: 0.7032 - val_accuracy: 0.6890\n",
      "Epoch 72/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7121 - val_loss: 0.6954 - val_accuracy: 0.6850\n",
      "Epoch 73/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.7140 - val_loss: 0.6818 - val_accuracy: 0.7008\n",
      "Epoch 74/250\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.6984 - val_loss: 0.7012 - val_accuracy: 0.6614\n",
      "Epoch 75/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5554 - accuracy: 0.7160 - val_loss: 0.7010 - val_accuracy: 0.6575\n",
      "Epoch 76/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.6907 - val_loss: 0.7454 - val_accuracy: 0.6732\n",
      "Epoch 77/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.7101 - val_loss: 0.6917 - val_accuracy: 0.6575\n",
      "Epoch 78/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5767 - accuracy: 0.7082 - val_loss: 0.7054 - val_accuracy: 0.6614\n",
      "Epoch 79/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.7004 - val_loss: 0.7269 - val_accuracy: 0.6614\n",
      "Epoch 80/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.7121 - val_loss: 0.6705 - val_accuracy: 0.6772\n",
      "Epoch 81/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7160 - val_loss: 0.6849 - val_accuracy: 0.6850\n",
      "Epoch 82/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5767 - accuracy: 0.7140 - val_loss: 0.6811 - val_accuracy: 0.6732\n",
      "Epoch 83/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.7023 - val_loss: 0.6956 - val_accuracy: 0.6929\n",
      "Epoch 84/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5635 - accuracy: 0.7140 - val_loss: 0.6820 - val_accuracy: 0.6811\n",
      "Epoch 85/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7043 - val_loss: 0.6986 - val_accuracy: 0.6693\n",
      "Epoch 86/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.7062 - val_loss: 0.6974 - val_accuracy: 0.6772\n",
      "Epoch 87/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5766 - accuracy: 0.7062 - val_loss: 0.7005 - val_accuracy: 0.6850\n",
      "Epoch 88/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.6946 - val_loss: 0.7137 - val_accuracy: 0.6535\n",
      "Epoch 89/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5867 - accuracy: 0.7121 - val_loss: 0.7003 - val_accuracy: 0.6772\n",
      "Epoch 90/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.6965 - val_loss: 0.7272 - val_accuracy: 0.6693\n",
      "Epoch 91/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.6907 - val_loss: 0.7079 - val_accuracy: 0.6850\n",
      "Epoch 92/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5858 - accuracy: 0.7043 - val_loss: 0.7000 - val_accuracy: 0.6929\n",
      "Epoch 93/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.6926 - val_loss: 0.7086 - val_accuracy: 0.6654\n",
      "Epoch 94/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.7023 - val_loss: 0.7349 - val_accuracy: 0.6772\n",
      "Epoch 95/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.7062 - val_loss: 0.6981 - val_accuracy: 0.6811\n",
      "Epoch 96/250\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5771 - accuracy: 0.7004 - val_loss: 0.6915 - val_accuracy: 0.6614\n",
      "Epoch 97/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5720 - accuracy: 0.6965 - val_loss: 0.7252 - val_accuracy: 0.6535\n",
      "Epoch 98/250\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7101 - val_loss: 0.6603 - val_accuracy: 0.6850\n",
      "Epoch 99/250\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7023 - val_loss: 0.6751 - val_accuracy: 0.6535\n",
      "Epoch 100/250\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7198 - val_loss: 0.6893 - val_accuracy: 0.6654\n",
      "Epoch 101/250\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.7101 - val_loss: 0.6804 - val_accuracy: 0.6772\n",
      "Epoch 102/250\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.7043 - val_loss: 0.6694 - val_accuracy: 0.6575\n",
      "Epoch 103/250\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.6984 - val_loss: 0.6866 - val_accuracy: 0.6693\n",
      "Epoch 104/250\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.7082 - val_loss: 0.6904 - val_accuracy: 0.6575\n",
      "Epoch 105/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.7101 - val_loss: 0.6972 - val_accuracy: 0.6535\n",
      "Epoch 106/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5797 - accuracy: 0.7140 - val_loss: 0.6901 - val_accuracy: 0.6969\n",
      "Epoch 107/250\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.7062 - val_loss: 0.7146 - val_accuracy: 0.6496\n",
      "Epoch 108/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7140 - val_loss: 0.7661 - val_accuracy: 0.6654\n",
      "Epoch 109/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.6926 - val_loss: 0.7225 - val_accuracy: 0.6535\n",
      "Epoch 110/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5716 - accuracy: 0.7062 - val_loss: 0.7269 - val_accuracy: 0.6732\n",
      "Epoch 111/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5719 - accuracy: 0.7062 - val_loss: 0.7041 - val_accuracy: 0.6496\n",
      "Epoch 112/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5614 - accuracy: 0.7140 - val_loss: 0.6691 - val_accuracy: 0.6693\n",
      "Epoch 113/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.7160 - val_loss: 0.6959 - val_accuracy: 0.6496\n",
      "Epoch 114/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7121 - val_loss: 0.7009 - val_accuracy: 0.6614\n",
      "Epoch 115/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.7082 - val_loss: 0.7113 - val_accuracy: 0.6614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.7121 - val_loss: 0.6884 - val_accuracy: 0.6693\n",
      "Epoch 117/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7140 - val_loss: 0.7332 - val_accuracy: 0.6496\n",
      "Epoch 118/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5593 - accuracy: 0.7121 - val_loss: 0.6954 - val_accuracy: 0.6693\n",
      "Epoch 119/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5610 - accuracy: 0.7062 - val_loss: 0.7143 - val_accuracy: 0.6693\n",
      "Epoch 120/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.7043 - val_loss: 0.7005 - val_accuracy: 0.6575\n",
      "Epoch 121/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.7023 - val_loss: 0.7254 - val_accuracy: 0.6693\n",
      "Epoch 122/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5753 - accuracy: 0.7004 - val_loss: 0.6874 - val_accuracy: 0.6575\n",
      "Epoch 123/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5658 - accuracy: 0.7121 - val_loss: 0.6714 - val_accuracy: 0.6732\n",
      "Epoch 124/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5943 - accuracy: 0.6809 - val_loss: 0.7213 - val_accuracy: 0.6299\n",
      "Epoch 125/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5734 - accuracy: 0.7121 - val_loss: 0.6762 - val_accuracy: 0.6693\n",
      "Epoch 126/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5680 - accuracy: 0.7082 - val_loss: 0.6800 - val_accuracy: 0.6693\n",
      "Epoch 127/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5555 - accuracy: 0.7062 - val_loss: 0.7286 - val_accuracy: 0.6496\n",
      "Epoch 128/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5645 - accuracy: 0.6926 - val_loss: 0.6814 - val_accuracy: 0.6732\n",
      "Epoch 129/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5680 - accuracy: 0.7140 - val_loss: 0.7124 - val_accuracy: 0.6614\n",
      "Epoch 130/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5586 - accuracy: 0.7218 - val_loss: 0.6917 - val_accuracy: 0.6654\n",
      "Epoch 131/250\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.7004 - val_loss: 0.7408 - val_accuracy: 0.6339\n",
      "Epoch 132/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.7062 - val_loss: 0.6878 - val_accuracy: 0.6693\n",
      "Epoch 133/250\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5696 - accuracy: 0.6984 - val_loss: 0.6939 - val_accuracy: 0.6772\n",
      "Epoch 134/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.7101 - val_loss: 0.7035 - val_accuracy: 0.6772\n",
      "Epoch 135/250\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.7082 - val_loss: 0.6875 - val_accuracy: 0.6535\n",
      "Epoch 136/250\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7101 - val_loss: 0.6762 - val_accuracy: 0.6732\n",
      "Epoch 137/250\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7082 - val_loss: 0.6869 - val_accuracy: 0.6614\n",
      "Epoch 138/250\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.7101 - val_loss: 0.6756 - val_accuracy: 0.6811\n",
      "Epoch 139/250\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7160 - val_loss: 0.7074 - val_accuracy: 0.6535\n",
      "Epoch 140/250\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.7082 - val_loss: 0.7590 - val_accuracy: 0.6575\n",
      "Epoch 141/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.7121 - val_loss: 0.6943 - val_accuracy: 0.6535\n",
      "Epoch 142/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.7043 - val_loss: 0.6949 - val_accuracy: 0.6772\n",
      "Epoch 143/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.7062 - val_loss: 0.6929 - val_accuracy: 0.6575\n",
      "Epoch 144/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.7062 - val_loss: 0.6970 - val_accuracy: 0.6614\n",
      "Epoch 145/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.7062 - val_loss: 0.7004 - val_accuracy: 0.6575\n",
      "Epoch 146/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.7062 - val_loss: 0.6772 - val_accuracy: 0.6732\n",
      "Epoch 147/250\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7101 - val_loss: 0.6694 - val_accuracy: 0.6772\n",
      "Epoch 148/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5592 - accuracy: 0.7121 - val_loss: 0.6783 - val_accuracy: 0.6772\n",
      "Epoch 149/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.7004 - val_loss: 0.7230 - val_accuracy: 0.6496\n",
      "Epoch 150/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.6984 - val_loss: 0.7023 - val_accuracy: 0.6496\n",
      "Epoch 151/250\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.7140 - val_loss: 0.7239 - val_accuracy: 0.6693\n",
      "Epoch 152/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5693 - accuracy: 0.7160 - val_loss: 0.7119 - val_accuracy: 0.6417\n",
      "Epoch 153/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5592 - accuracy: 0.7179 - val_loss: 0.7127 - val_accuracy: 0.6732\n",
      "Epoch 154/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.7101 - val_loss: 0.7077 - val_accuracy: 0.6535\n",
      "Epoch 155/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7082 - val_loss: 0.6827 - val_accuracy: 0.6614\n",
      "Epoch 156/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5591 - accuracy: 0.7004 - val_loss: 0.6726 - val_accuracy: 0.6535\n",
      "Epoch 157/250\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5799 - accuracy: 0.7023 - val_loss: 0.6580 - val_accuracy: 0.6929\n",
      "Epoch 158/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.7062 - val_loss: 0.6673 - val_accuracy: 0.6693\n",
      "Epoch 159/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.7140 - val_loss: 0.6861 - val_accuracy: 0.6850\n",
      "Epoch 160/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5655 - accuracy: 0.6907 - val_loss: 0.6954 - val_accuracy: 0.6535\n",
      "Epoch 161/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.7082 - val_loss: 0.6996 - val_accuracy: 0.6614\n",
      "Epoch 162/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5588 - accuracy: 0.7062 - val_loss: 0.6920 - val_accuracy: 0.6850\n",
      "Epoch 163/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5796 - accuracy: 0.7043 - val_loss: 0.6911 - val_accuracy: 0.6575\n",
      "Epoch 164/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5639 - accuracy: 0.7101 - val_loss: 0.6770 - val_accuracy: 0.6811\n",
      "Epoch 165/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7140 - val_loss: 0.6803 - val_accuracy: 0.6772\n",
      "Epoch 166/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.7004 - val_loss: 0.6994 - val_accuracy: 0.6654\n",
      "Epoch 167/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.7179 - val_loss: 0.7300 - val_accuracy: 0.6575\n",
      "Epoch 168/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.7004 - val_loss: 0.7075 - val_accuracy: 0.6575\n",
      "Epoch 169/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5619 - accuracy: 0.7082 - val_loss: 0.6948 - val_accuracy: 0.6890\n",
      "Epoch 170/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.7140 - val_loss: 0.6958 - val_accuracy: 0.6614\n",
      "Epoch 171/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.6887 - val_loss: 0.6912 - val_accuracy: 0.6654\n",
      "Epoch 172/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 0.7140 - val_loss: 0.6908 - val_accuracy: 0.6614\n",
      "Epoch 173/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7101 - val_loss: 0.7060 - val_accuracy: 0.6811\n",
      "Epoch 174/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5642 - accuracy: 0.7023 - val_loss: 0.7013 - val_accuracy: 0.6496\n",
      "Epoch 175/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5513 - accuracy: 0.7160 - val_loss: 0.7182 - val_accuracy: 0.6575\n",
      "Epoch 176/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.7062 - val_loss: 0.7057 - val_accuracy: 0.6535\n",
      "Epoch 177/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5608 - accuracy: 0.7140 - val_loss: 0.7285 - val_accuracy: 0.6654\n",
      "Epoch 178/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.7179 - val_loss: 0.7177 - val_accuracy: 0.6535\n",
      "Epoch 179/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.7062 - val_loss: 0.6459 - val_accuracy: 0.6772\n",
      "Epoch 180/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.7043 - val_loss: 0.6489 - val_accuracy: 0.6614\n",
      "Epoch 181/250\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5720 - accuracy: 0.6887 - val_loss: 0.6782 - val_accuracy: 0.6614\n",
      "Epoch 182/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7101 - val_loss: 0.6639 - val_accuracy: 0.6575\n",
      "Epoch 183/250\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5583 - accuracy: 0.7179 - val_loss: 0.6474 - val_accuracy: 0.6772\n",
      "Epoch 184/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5586 - accuracy: 0.7082 - val_loss: 0.6583 - val_accuracy: 0.6614\n",
      "Epoch 185/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5543 - accuracy: 0.7043 - val_loss: 0.6658 - val_accuracy: 0.6850\n",
      "Epoch 186/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5558 - accuracy: 0.7043 - val_loss: 0.6542 - val_accuracy: 0.6614\n",
      "Epoch 187/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5750 - accuracy: 0.7062 - val_loss: 0.6701 - val_accuracy: 0.6535\n",
      "Epoch 188/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5523 - accuracy: 0.7198 - val_loss: 0.6764 - val_accuracy: 0.6614\n",
      "Epoch 189/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5835 - accuracy: 0.6751 - val_loss: 0.6904 - val_accuracy: 0.6575\n",
      "Epoch 190/250\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5547 - accuracy: 0.7101 - val_loss: 0.6792 - val_accuracy: 0.6575\n",
      "Epoch 191/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.7101 - val_loss: 0.6865 - val_accuracy: 0.6772\n",
      "Epoch 192/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5535 - accuracy: 0.7101 - val_loss: 0.6817 - val_accuracy: 0.6850\n",
      "Epoch 193/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5540 - accuracy: 0.7140 - val_loss: 0.6656 - val_accuracy: 0.6811\n",
      "Epoch 194/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7198 - val_loss: 0.6848 - val_accuracy: 0.6614\n",
      "Epoch 195/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5535 - accuracy: 0.7101 - val_loss: 0.6804 - val_accuracy: 0.6772\n",
      "Epoch 196/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.7101 - val_loss: 0.6710 - val_accuracy: 0.6575\n",
      "Epoch 197/250\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5569 - accuracy: 0.7237 - val_loss: 0.6646 - val_accuracy: 0.6850\n",
      "Epoch 198/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5543 - accuracy: 0.7082 - val_loss: 0.6850 - val_accuracy: 0.6614\n",
      "Epoch 199/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.6946 - val_loss: 0.6762 - val_accuracy: 0.6654\n",
      "Epoch 200/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.7121 - val_loss: 0.6664 - val_accuracy: 0.6693\n",
      "Epoch 201/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.7004 - val_loss: 0.6940 - val_accuracy: 0.6575\n",
      "Epoch 202/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5665 - accuracy: 0.7062 - val_loss: 0.6746 - val_accuracy: 0.6654\n",
      "Epoch 203/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.7101 - val_loss: 0.6927 - val_accuracy: 0.6535\n",
      "Epoch 204/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5609 - accuracy: 0.7023 - val_loss: 0.6837 - val_accuracy: 0.6732\n",
      "Epoch 205/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.7218 - val_loss: 0.6685 - val_accuracy: 0.6535\n",
      "Epoch 206/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.6926 - val_loss: 0.6674 - val_accuracy: 0.6535\n",
      "Epoch 207/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5588 - accuracy: 0.7082 - val_loss: 0.6854 - val_accuracy: 0.6575\n",
      "Epoch 208/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.7121 - val_loss: 0.7027 - val_accuracy: 0.6614\n",
      "Epoch 209/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5508 - accuracy: 0.7218 - val_loss: 0.6832 - val_accuracy: 0.6457\n",
      "Epoch 210/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.7101 - val_loss: 0.7117 - val_accuracy: 0.6575\n",
      "Epoch 211/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.7101 - val_loss: 0.6891 - val_accuracy: 0.6575\n",
      "Epoch 212/250\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5556 - accuracy: 0.7160 - val_loss: 0.6837 - val_accuracy: 0.6850\n",
      "Epoch 213/250\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5707 - accuracy: 0.7257 - val_loss: 0.6878 - val_accuracy: 0.6614\n",
      "Epoch 214/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7101 - val_loss: 0.7073 - val_accuracy: 0.6732\n",
      "Epoch 215/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.7179 - val_loss: 0.6645 - val_accuracy: 0.6575\n",
      "Epoch 216/250\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5513 - accuracy: 0.7062 - val_loss: 0.6583 - val_accuracy: 0.6772\n",
      "Epoch 217/250\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5489 - accuracy: 0.7160 - val_loss: 0.6786 - val_accuracy: 0.6614\n",
      "Epoch 218/250\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5552 - accuracy: 0.7160 - val_loss: 0.6450 - val_accuracy: 0.6654\n",
      "Epoch 219/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.7198 - val_loss: 0.6751 - val_accuracy: 0.6575\n",
      "Epoch 220/250\n",
      "52/52 [==============================] - ETA: 0s - loss: 0.5576 - accuracy: 0.69 - 0s 3ms/step - loss: 0.5577 - accuracy: 0.7062 - val_loss: 0.6519 - val_accuracy: 0.6575\n",
      "Epoch 221/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.7023 - val_loss: 0.6709 - val_accuracy: 0.6575\n",
      "Epoch 222/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.7160 - val_loss: 0.6495 - val_accuracy: 0.6811\n",
      "Epoch 223/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5654 - accuracy: 0.7101 - val_loss: 0.6504 - val_accuracy: 0.6496\n",
      "Epoch 224/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.7121 - val_loss: 0.6659 - val_accuracy: 0.6575\n",
      "Epoch 225/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5678 - accuracy: 0.7101 - val_loss: 0.6605 - val_accuracy: 0.6535\n",
      "Epoch 226/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.7043 - val_loss: 0.6599 - val_accuracy: 0.6614\n",
      "Epoch 227/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.7140 - val_loss: 0.6577 - val_accuracy: 0.6575\n",
      "Epoch 228/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7218 - val_loss: 0.6532 - val_accuracy: 0.6772\n",
      "Epoch 229/250\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.7160 - val_loss: 0.6600 - val_accuracy: 0.6890\n",
      "Epoch 230/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.7140 - val_loss: 0.6890 - val_accuracy: 0.6693\n",
      "Epoch 231/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5546 - accuracy: 0.7062 - val_loss: 0.6759 - val_accuracy: 0.6614\n",
      "Epoch 232/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.7043 - val_loss: 0.6654 - val_accuracy: 0.6929\n",
      "Epoch 233/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.7160 - val_loss: 0.6853 - val_accuracy: 0.6732\n",
      "Epoch 234/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7082 - val_loss: 0.7183 - val_accuracy: 0.6378\n",
      "Epoch 235/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.7043 - val_loss: 0.6593 - val_accuracy: 0.6614\n",
      "Epoch 236/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.7062 - val_loss: 0.6511 - val_accuracy: 0.6654\n",
      "Epoch 237/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.6946 - val_loss: 0.6959 - val_accuracy: 0.6654\n",
      "Epoch 238/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5674 - accuracy: 0.7043 - val_loss: 0.6541 - val_accuracy: 0.6850\n",
      "Epoch 239/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.7043 - val_loss: 0.6746 - val_accuracy: 0.6496\n",
      "Epoch 240/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5528 - accuracy: 0.7140 - val_loss: 0.6762 - val_accuracy: 0.6535\n",
      "Epoch 241/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.7140 - val_loss: 0.6794 - val_accuracy: 0.6535\n",
      "Epoch 242/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.7237 - val_loss: 0.6640 - val_accuracy: 0.6614\n",
      "Epoch 243/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5539 - accuracy: 0.7101 - val_loss: 0.6593 - val_accuracy: 0.6811\n",
      "Epoch 244/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.7179 - val_loss: 0.6872 - val_accuracy: 0.6890\n",
      "Epoch 245/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7179 - val_loss: 0.7178 - val_accuracy: 0.6614\n",
      "Epoch 246/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.7004 - val_loss: 0.6730 - val_accuracy: 0.6693\n",
      "Epoch 247/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5489 - accuracy: 0.7140 - val_loss: 0.6879 - val_accuracy: 0.6654\n",
      "Epoch 248/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5538 - accuracy: 0.7082 - val_loss: 0.6884 - val_accuracy: 0.6496\n",
      "Epoch 249/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.7062 - val_loss: 0.6997 - val_accuracy: 0.6811\n",
      "Epoch 250/250\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7043 - val_loss: 0.6377 - val_accuracy: 0.6575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d793f9b400>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X, Y, validation_split=0.33, epochs=250, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 1ms/step - loss: 0.5666 - accuracy: 0.7044\n",
      "accuracy: 70.44%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
